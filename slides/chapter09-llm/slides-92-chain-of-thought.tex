\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

%\newcommand{\titlefigure}{figure/gpt_sq.png}
\newcommand{\learninggoals}{
\item illustrate chain-of-thought and point out the benefits it brings to LLMs
\item illustrate tree-of-thought and point out the benefits it brings to LLMs 
}

\definecolor{texblue}{rgb}{0, 0, 1}
\def\myblue#1{\textcolor{texblue}{#1}}

\title{Chain-of-thought Prompting}
% \author{}
\institute{\href{https://slds-lmu.github.io/lecture_dl4nlp/}{slds-lmu.github.io/lecture\_dl4nlp}}
\date{}

\begin{document}
\lecturechapter{Large Language Models (LLMs)}
\lecture{Deep Learning for NLP}

% ------------------------------------------------------------------------------ 

\begin{vbframe}{chain-of-though motivation}

\vfill

How to boost the reasoning capabilities of LLMs? \citebutton{Wei et al., 2021}{https://arxiv.org/abs/2109.01652}

\begin{itemize}
\item Use formal approaches, e.g., logic, symbolic reasoning
    \begin{itemize}
    \item Example: \citebutton{BeliefBank}{https://arxiv.org/abs/2109.14723}
\item Difficult to train and deploy, not widely used
    \end{itemize}
\item Standard few-shot learning via prompting works for many tasks
    \begin{itemize}
    \item Still, it works poorly on many tasks that require reasoning
    \end{itemize}
\item Chain of thought (CoT) prompting
    \begin{itemize}
    \item A new form of few-shot prompting
    \item Prompts in the form <input, \textit{chain of thought}, output>
    \item chain of thought:\\ series of reasoning steps that
    lead to the final answer
    \item applications: complex, commonsense, symbolic
    reasoning tasks etc
    \end{itemize}

\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------ 

\begin{vbframe}{Chain-of-thought prompting paradigm}

\vfill

%\textbf{CoT enables LLMs to tackle complex arithmetic, commonsense and symbolic reasoning tasks.}

\begin{figure}
    \centering
    \includegraphics{figure/chain_of_thought.png}\\
    \citebutton{Source: Wei et al., 2022}{https://arxiv.org/pdf/2201.11903.pdf}
\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------ 

\begin{vbframe}{Chain-of-thought prompting paradigm}

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/chain_of_thought2.png}
\end{figure}

\end{vbframe}

% ------------------------------------------------------------------------------


\begin{vbframe}{Benefits of Chain-of-thought}

\vfill

\begin{itemize}
    \item Decompose multi-step problems and thus allocate more compute to problems requiring more reasoning steps
    \item By describing the reasoning, interpretability is increased. It provides the possibility to observe where reasoning went wrong
    \item It is closer to how humans solve tasks using language
    \item Existing large language models can do
    chain-of-thought reasoning if given a well designed prompt.
\end{itemize}

\vfill

\end{vbframe}


% ------------------------------------------------------------------------------

\begin{vbframe}{Examples for chain of thought}

\vfill

\textbf{Examples of $<$input, chain of thought, output$>$ triples for  commonsense and symbolic reasoning}

    \citebutton{Source: Wei et al., 2022}{https://arxiv.org/pdf/2201.11903.pdf}


\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex1.png}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex2.png}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex3.png}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex4.png}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex5.png}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Examples}

\vfill

\begin{figure}
    \centering
    \includegraphics[height=7cm]{figure/cotex6.png}
\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{CoT improves arithmetic}

%\vfill

SVAMP: math word problems with varying structures; MAWPS:
repository unifying math problems from different sources;
    \citebutton{Source: Wei et al., 2022}{https://arxiv.org/pdf/2201.11903.pdf}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figure/cot_performance1.png}
\end{figure}

%\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{CoT improves commonsense}

\vfill

CSQA: Contains around 200K dialogs with a total of 1.6M
turns. Further, unlike existing large scale QA datasets
which contain simple questions that can be answered from a
single tuple, the questions in the dialogs require a larger
subgraph of the KG. 


\begin{figure}
    \centering
    \includegraphics{figure/cot_performance2.png}\\
    \citebutton{Source: Wei et al., 2022}{https://arxiv.org/pdf/2201.11903.pdf}
\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------ 

\begin{vbframe}{tree-of-thought: motivation}

\vfill

\begin{itemize}
\item The token-level and left-to-right decisions of the autoregressive mechanism pose a limitation for:
    \begin{itemize}
    \item Tasks where initial decisions play a pivotal role
    \item Tasks requiring exploration or strategic lookahead
    \end{itemize}
\item Potential strategy to solve those:
    \begin{itemize}
    \item Maintain and explore diverse alternatives instead of just picking one
    \item Evaluates current status and looks ahead or backtrack to make global decisions
    \end{itemize}

\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Tree-of-thought: prompting paradigm}

\vfill

Schematic illustrating various approaches to problem solving with LLMs. Each rectangle box represents a \textit{thought}, a coherent language sequence serving as an intermediate step toward problem solving.

\begin{figure}
    \centering
    \includegraphics{figure/tot_vs_cot.png}\\
\citebutton{Yao et al., 2023}{https://arxiv.org/pdf/2305.10601.pdf}
\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------


\begin{vbframe}{Tree-of-thought for creative writing}

\vfill

A step of deliberate search in a randomly picked Creative Writing task. Given the input, the LM samples five different plans, and then votes five times to decide which plan is best.
    
\begin{figure}
    \centering
    \includegraphics{figure/tot_creative_writing.png}\\
\citebutton{Yao et al., 2023}{https://arxiv.org/pdf/2305.10601.pdf}
\end{figure}

\vfill

\end{vbframe}

\begin{vbframe}{Tree-of-thought for creative writing (2)}

\vfill
    
\begin{figure}
\raisebox{0pt}[\height][\depth]{\hspace{-0.85cm}%
    \includegraphics[width=1.15\textwidth]{figure/totcreativebig.png}
}
\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{frame}{Chain of thought: What could go wrong?}

\vfill

\begin{itemize}
    \item Decompose complex problems into a sequence of reasoning steps
    \item By describing the reasoning, interpretability is increased. It provides the possibility to observe where reasoning went wrong
    \item It is closer to how humans solve tasks using language
    \item Existing large language models can do
    chain-of-thought reasoning if given a well designed prompt.

\item \ques What could go wrong?
% no guarantee that the reasoning given is the reasoning employed
% is this true for humans?
% only one answer, but what happens if there is no good single answer?
% clearly a great thing for the examples given, but how
%    typical is this for what we need from language models?
%    -> go back to six examples that were blown up
%    inearlier slides
\end{itemize}

\vfill

\end{frame}

\begin{frame}{Chain of thought: Why does it work?}

\vfill

\begin{itemize}
    \item \ques Why does it work?
% make clear that reasoning is required
% make clear what kind o reasoning is rquirecd
% allocate additional compute
% LLMs are good at finding their own mistakes if
%    they look over there own output
\end{itemize}

\vfill

\end{frame}



\endlecture
\end{document}
