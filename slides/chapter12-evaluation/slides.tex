\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}


\newcommand{\titlefigure}{figure/python.png} %TODO
\newcommand{\learninggoals}{
\item Understand how to evaluate LLMs 
\item Learn about pitfalls and challenges of evaluation
\item See some examples of behavioural testing of LLMs}

\renewcommand{\bfseries}{\mdseries}





\title{Pytorch Logic}
% \author{}
\institute{\href{https://slds-lmu.github.io/lecture_dl4nlp/}{slds-lmu.github.io/lecture\_dl4nlp}}
\date{}

\begin{document}
\lecturechapter{Lecture Evaluation}
\lecture{Deep Learning for NLP}

% ------------------------------------------------------------------------------

\begin{vbframe}{Overview}

\vfill
 \begin{itemize}
 \item Statistics and evaluation
 \item Challenges of evaluation
 \item The MIT EECS exams: a case study
 \item Behavioural testing
 \item Evaluation using LLMs
 \end{itemize}


\vfill

\end{vbframe}

% ------------------------------------------------------------------------------
\begin{vbframe}{Statistics Primer}

\vfill

\end{vbframe}


\begin{vbframe}{Let's say you read a paper...}

	\vfill
	… and the results section looks like this:
	\begin{table}
		\centering
		\begin{tabular}{l|r}
			\textbf{Model} & \textbf{Accuracy} \\
			\hline
			\textbf{Baseline} & 89.1 \\
			\textbf{Our Model} & 88.5 \\
		\end{tabular}
	\end{table}
	What questions would you ask? 

\vfill

\end{vbframe}

\begin{vbframe}{Reporting Standard Deviation}

	\includegraphics[width=0.6\textwidth]{evaluation_figures/standard_deviation_curve.png}
	\includegraphics[width=0.6\textwidth]{evaluation_figures/standard_deviation_formula.png} 
	

\vfill

\end{vbframe}


\begin{vbframe}{So they run both models 5 times and come back with this}
	\vfill
	\begin{table}
		\centering
		\begin{tabular}{l|r}
			\textbf{Model} & \textbf{Accuracy} \\
			\hline
			\textbf{Baseline} & 89.1 $\pm$ 0.3 \\
			\textbf{Our Model} & 88.5 $\pm$ 0.2\\
		\end{tabular}
	\end{table}

	\vfill

	Do we believe them now? Why or why not?

	And how do we decide this in a scientific way?
	   
\vfill

\end{vbframe}

\begin{vbframe}{Significance Testing}
	\vfill

	\begin{itemize}
		\item Our devil's advocate hypothesis: these models aren't different at all!
		\item At what point will we be convinced?
		\item Let's say: if there's only a 5\% chance that the better results are down to chance
		\item Even though they ran the experiments 5 times, it's possible that they just got lucky
	\end{itemize}

\end{vbframe}

\begin{vbframe}{Significance Testing}

	\includegraphics[width=0.9\textwidth]{evaluation_figures/significance_testing.png}

\end{vbframe}


\begin{vbframe}{They do a significance test}

	\vfill

	\begin{table}
		\centering
		\begin{tabular}{l|r}
			\textbf{Model} & \textbf{Accuracy} \\
			\hline
			\textbf{Baseline} & 89.1 $\pm$ 0.3 \\
			\textbf{Our Model} & 88.5 $\pm$ 0.2\\
		\end{tabular}
	\end{table}

	\vfill

	And report that their model was significantly ($p < 0.05$) better than the baseline.
	
\end{vbframe}

\begin{vbframe}{Do we now have complete faith in this evaluation?}

	\vfill
No, of course not.
\vfill
Why not?
\vfill
\end{vbframe}

\begin{vbframe}{Benchmark Contamination}

	As benchmark data becomes available online and large models are trained on gigantic web corpora, the test data may already have been in the training data and therefore very easy for the model.

	Contamination of common benchmarks in C4
	% include both images side by side
	\begin{figure}
		\centering
	  
		\subfloat[Input Contamination]{\includegraphics[width=0.40\textwidth]{evaluation_figures/contamination_input.png}}
		\hfill
		\subfloat[Label Contamination]{\includegraphics[width=0.40\textwidth]{evaluation_figures/contamination_label.png}}
	  
		\caption{Contamination of common benchmarks in C4}
	  \end{figure}

		
\end{vbframe}

\begin{vbframe}{Measuring the impact of data contamination}

	We can measure the impact of data contamination by increasing it intentionally in a controlled setting, and measuring the impact on downstream task performance.
	% include both images side by side
	\begin{columns}
		\column{0.4\textwidth}
		
		\includegraphics[width=0.4\textwidth]{evaluation_figures/exploitation_graph.png}
		\column{0.6\textwidth}
		\includegraphics[width=0.4\textwidth]{evaluation_figures/exploitation_barchart.png}
	  
	\end{columns}

% small text at the bottom
\tiny
Source: Magar and Schwartz, 2022
\end{vbframe}

\begin{vbframe}{Evaluation of Closed-Source Models}
	\vfill
	\begin{itemize}
		\item Data contamination becomes worse when you can‘t test what‘s in the data, because they don‘t tell you what the data was $\rightarrow$ assume that if something is on the internet, GPT-4 has seen it
		\item Only OpenAI can report on data contamination and we have to take their word for it
		\item Excluding benchmarks from the internet becomes impossible $\rightarrow$ either still take the results seriously, or come up with new benchmarks, which after a time will also be on the internet
	\end{itemize}

\end{vbframe}
	
\begin{vbframe}{The GPT-4 Technical Report}
	\vfill

	\includegraphics[width=\textwidth]{evaluation_figures/technical_report.png}
	\vfill

100 pages of PDF, but 80\% of it examples of GPT-4 output

\end{vbframe}
		
\begin{vbframe}{Metrics from the GPT-4 Techincal Report}

	\includegraphics[width=0.8\textwidth]{evaluation_figures/gpt_exam_results.png}

Evaluating not on benchmarks, but on exams made for humans.

What are some problems with this?

\end{vbframe}

\begin{vbframe}{Prompt Engineering}

	\vfill

\begin{itemize}
	\item Any result achieved by prompting can only be a lower bound for what the LM can theoretically do, because there may be a better prompt that we haven‘t thought of
	\item Thinking of every possible prompt is difficult
	\item Possible solution: automatically mining different prompts with dependency-based filtering, or paraphrasing
	\item Ensembling many different prompts (expensive)
\end{itemize}
\end{vbframe}


\begin{vbframe}{Prompt Mining}
	\vfill

	\includegraphics[width=\textwidth]{evaluation_figures/mined_prompts.png}

	\begin{itemize}
		\item we can mine a prompt by looking for ways that this information was expressed in text
		\item the result might not be the most straightforward way of expressing something, but a more commonly used one
		\item this can achieve significant gains depending on the prompt
	\end{itemize}
	\tiny
	Source: Jiang et al. 2020
\end{vbframe}	

\begin{vbframe}{Prompt Ensembling}
	\vfill

	\includegraphics[width=\textwidth]{evaluation_figures/ensembled_prompts.png}

	\begin{itemize}
		\item we can use prompts at the same time with ensembling
		\item the end result is a weighted sum of the results of the individual prompts
		\item we can learn the weights on a validation set and achieve significant gains
	\end{itemize}
	\tiny
	Source: Jiang et al. 2020
\end{vbframe}	

\begin{vbframe}{Surface Form Competition}

	\begin{columns}
		\column{0.5\textwidth}

	\includegraphics[width=0.5\textwidth]{evaluation_figures/competition.png}
	\column{0.5\textwidth}

	\begin{itemize}
		\item we have to consider all possible strings that might represent a correct answer
		\item we might have to add probabilities if we have access to them
	\end{itemize}
	\end{columns}
	\tiny
	Source: Holtzman et al. 2021
\end{vbframe}	

\begin{vbframe}{Calibration}

	\includegraphics[width=0.8\textwidth]{evaluation_figures/calibration_sentiment.png}
	\vfill
	Does the choice of few shots influence the results, and how can we mitigate this?
	\tiny
	Source: Zhao et al. 2021
\end{vbframe}	

\begin{vbframe}{Training examples, permutation, and prompt format all influence the results}
	\vfill

	\includegraphics[width=\textwidth]{evaluation_figures/prompt_variation.png}
\end{vbframe}	

\begin{vbframe}{Balancing the class of the shots matters}
	\vfill

	\includegraphics[width=\textwidth]{evaluation_figures/shot_balancing.png}
\end{vbframe}	

\begin{vbframe}{The solution: Contextual Calibration}

	\begin{itemize}
		\item Design a `blank' prompt with zero information about the sentiment
		\item Measure the probability assigned by the model to Positive and Negative
		\item This should be 50/50 but might actually be e.g. 60/40
		\item Learn a simple transformation based on this probability, so that the scores are now 50/50
	\end{itemize}
	\vfill
	\includegraphics[width=0.8\textwidth]{evaluation_figures/empty_prompt.png}
\end{vbframe}

\begin{vbframe}{A negative case study}

	No, GPT-4 can't ace the MIT EECS exams.

	\vfill
	\tiny
	Source: www.raunakdoes.dev
\end{vbframe}	

\begin{vbframe}{Initial Excitement on Twitter}

	\includegraphics[width=0.5\textwidth]{evaluation_figures/twitter_mit.png}
\end{vbframe}	

\begin{vbframe}{Unsolvable Questions make up 4\% of the test set}

	\includegraphics[width=\textwidth]{evaluation_figures/unsolvable_1.png}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/unsolvable_2.png}

\end{vbframe}

\begin{vbframe}{Overlap of Few-Shot Examples with Test Data}

	\includegraphics[width=0.8\textwidth]{evaluation_figures/overlap.png}

\end{vbframe}

\begin{vbframe}{Evaluating GPT-4 with GPT-4}
	\vfill

	\begin{itemize}
		\item GPT-4 is given a grading prompt, the question, the correct solution, and its own reply
		\item A prompt cascade is used:

		\includegraphics[width=\textwidth]{evaluation_figures/critiques.png}

		\item the model can try again until a correct answer is reached
		\item this guarantees a correct answer for multiple-choice questions (16\% of the test set)
	\end{itemize}
\end{vbframe}

\begin{vbframe}{Bugs}

Mixing up the question and the system prompt:
You are \{question\} Your task is to answer the following question: Question: \{system\}

Expert prompts were generated by
\begin{itemize}
	\item asking ChatGPT who a good expert would be 
	\item separating the output by commas
	\item taking the first 3 as experts
\end{itemize}
Resulting in experts like:
\begin{itemize}
	\item "It is difficult to pinpoint specific individuals who would be most capable of solving this question"
	\item "as many computer scientists and mathematicians with expertise in digital logic"
	\item "and number systems would be well-equipped to handle this problem. However"
\end{itemize}
\end{vbframe}


\begin{vbframe}{Big Evaluation Projects}



\end{vbframe}

\begin{vbframe}{BigBench}

	\includegraphics[width=0.5\textwidth]{evaluation_figures/bigbench_authors.png}

	Beyond the Imitation Game Benchmark
\begin{itemize}
	\item 204 tasks contributed by 450 authors
	\item includes evaluation on all tasks from big models that were available at the time
	\item emphasis on tasks that are still challenging for GPT-size models
\end{itemize}
\end{vbframe}

\begin{vbframe}{Motivation: existing benchmarks are saturating}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/bigbench_motivation.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Tasks designed to be challenging}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/bigbench_challenging.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Some interesting tasks}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/bigbench_interesting.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/inverse_scaling.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/resisting_correction.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/memo_trap.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/redefine.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=0.9\textwidth]{evaluation_figures/prompt_injection.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/modus_tollens.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/pattern_match_suppression.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/unknown.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=0.9\textwidth]{evaluation_figures/hindsight_neglect.png}
	\vfill
\end{vbframe}

\begin{vbframe}{The Inverse Scaling Prize}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/repetitive_algebra.png}
	\vfill
\end{vbframe}

\begin{vbframe}{DynaBench}
	\vfill
	\includegraphics[width=0.8\textwidth]{evaluation_figures/dynabench_task.png}
	\vfill
\end{vbframe}

\begin{vbframe}{DynaBench}

	\includegraphics[width=0.8\textwidth]{evaluation_figures/dynabench_overview.png}

\end{vbframe}

\begin{vbframe}{Targeted Behavioural Testing}

\end{vbframe}

\begin{vbframe}{Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly	}

	\includegraphics[width=0.9\textwidth]{evaluation_figures/birds.png}
\end{vbframe}

\begin{vbframe}{oLMpics - On What Language Model Pre-training Captures}
	\vfill
	Central problem: if we're finetuning with our probing task, how can we tell apart which knowledge the model already had and which we're giving it by finetuning?
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/olmpics.png}
	\vfill
\end{vbframe}

\begin{vbframe}{oLMpics Probing Setup}
	\vfill
	\begin{itemize}
		\item red squares: RoBERTa-L's accuracy during finetuning
		\item red circles: simple prompt like "cat [blah/yah] mouse"
		\item green triangles: baseline non-pretrained model
	\end{itemize}
	\includegraphics[width=0.7\textwidth]{evaluation_figures/olmpics_setup.png}
	\vfill
\end{vbframe}

\begin{vbframe}{oLMpics Results}

	\includegraphics[width=0.7\textwidth]{evaluation_figures/olmpics_results.png}
\end{vbframe}

\begin{vbframe}{Behavioral Testing of NLP Models with CheckList}

	What are all the things we need to test before deploying a model?

	\includegraphics[width=0.7\textwidth]{evaluation_figures/checklist_start.png}
\end{vbframe}

\begin{vbframe}{Behavioral Testing of NLP Models with CheckList}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/checklist_vocab.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Behavioral Testing of NLP Models with CheckList}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/checklist_negation.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Diagnosing Syntactic Heuristics in Natural Language Inference}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/nli_start.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Diagnosing Syntactic Heuristics in Natural Language Inference}

	\includegraphics[width=\textwidth]{evaluation_figures/nli_examples.png}
\end{vbframe}

\begin{vbframe}{Diagnosing Syntactic Heuristics in Natural Language Inference}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/nli_results.png}
	\vfill
\end{vbframe}

\begin{vbframe}{Should we use GPT to evaluate itself?}
	\vfill
	\includegraphics[width=\textwidth]{evaluation_figures/gpt_self_eval.png}
	\vfill
\end{vbframe}

\begin{vbframe}{No}
	Advantages
	\begin{itemize}
	\item cheap
	\item fast
	\item reproducible
	\item samples independent of each other
	\item avoids exposing humans to potentially harmful content
	\end{itemize}
	\vfill
	Disadvantages
	\begin{itemize}
	\item unpredictable
	\item limited explainability
	\item doesn't correlate well enough with human judgments
	\end{itemize}
	\includegraphics[width=0.3\textwidth]{evaluation_figures/bad_correlation.png}

\end{vbframe}

\begin{vbframe}{A counterexample: evaluating machine translation}
\end{vbframe}

\begin{vbframe}{Evaluating machine translation}
	\vfill
	\begin{itemize}
		\item there are many different correct translations for one sentence
		\item most of those are not in the training data
		\item evaluation is typically performed at the sentence level, disregarding larger fluency and coherence problems
		\item human evaluation is expensive and slow
	\end{itemize}
	\vfill
\end{vbframe}

\begin{vbframe}{Evaluating machine translation}
	Comparing a MT translation to a reference translation
	\begin{itemize}
		\item Adequacy: is the meaning translated correctly, compared to the reference translation?
		\item Fluency: is the output grammatical and fluent, compared to the reference translation, or in isolation?
	\end{itemize}
	\vfill
	Alternative: human preference ranking of MT output
	\begin{itemize}
		\item more intuitive, less need for criteria
		\item difficult for long sequences
	\end{itemize}
\end{vbframe}

\begin{vbframe}{What do we want from an automated metric?}
	\vfill
	\begin{itemize}
		\item highly correlated with human judgments
		\item sensitive to small differences in quality
		\item consistent: same system on similar text should produce similar scores
		\item reliable: MT systems with similar scores will perform similarly
		\item general: applicable to all domains and scenarios
		\item fast and lightweight
	\end{itemize}
\end{vbframe}

\begin{vbframe}{The BLEU Score}
	Reference: `The Iraqi weapons are to be handed over to the army within two weeks'
	\vfill
	MT Output: `in two weeks Iraq's weapons will give army'
	\vfill
	Weighted geometric average of n-gram precisions for $n<=4$
	\begin{itemize}
		\item 1-gram precision: 4/8
		\item 2-gram precision: 1/7
		\item 3-gram precision: 0/6
		\item 4-gram precision: 0/5
		\item BLEU score: 0
	\end{itemize}
\end{vbframe}

\begin{vbframe}{Additional components in BLEU}
	MT Output: `the the the the the' will lead to a high unigram score 
	
	$\rightarrow$ clip at two (max count of the word in any reference), therefore 1-gram precision is 2/5
	\vfill
	MT Output: `the Iraqi weapons will' 
	
	$\rightarrow$ perfect BLEU score, but too short $\rightarrow$ brevity penalty
\end{vbframe}

\begin{vbframe}{Comparability Issues with BLEU scores}
	\vfill
	\begin{itemize}
		\item BLEU is underspecified and has parameters, like the number of references, exact length penalty, the smoothing, ...
		\item preprocessing has a large effect on BLEU scores
		\item details are often not supplied
		\item character- vs. word-level
		\item not comparable across languages or even datasets
	\end{itemize}
	\vfill
	$\rightarrow$ SacreBLEU: standardised python script for BLEU
\end{vbframe}

\begin{vbframe}{A possible solution: neural trained metrics}
	\vfill
	\begin{itemize}
		\item Shared Task at WMT: the Metrics task
		\item provided: source sentences, MT outputs, and reference translations
		\item task: build a metric that achieves high correlation with human judgment of the MT outputs
		\item BLEU performs badly, the best metrics are trained and neural
	\end{itemize}
	\includegraphics[width=0.5\textwidth]{evaluation_figures/neural_empty.png}
\end{vbframe}

\begin{vbframe}{One more problem: Translationese}
	\vfill
	Reference texts for metrics are often professional translations, which are vulnerable to Translationese
	\begin{itemize}
		\item Source Interference: replication of patterns from the target language
		\item Normalisation: translators use more conservative, formal language
		\item Implicitation: translated text might be more implicit than source text
		\item Explicitation: translated text might be more explicit than the source
		\item Simplification: translators might simplify the source text

	\end{itemize}
	\vfill
\end{vbframe}


\endlecture
\end{document}
