\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

%\newcommand{\titlefigure}{figure/gpt_sq.png}
\newcommand{\learninggoals}{
\item Understand biases inherent to GPT
\item Get a feeling for the cost and environmental impact}
\definecolor{texblue}{rgb}{0, 0, 1}
\def\myblue#1{\textcolor{texblue}{#1}}

\title{Discussion: Ethics and Cost}
% \author{}
\institute{\href{https://slds-lmu.github.io/lecture_dl4nlp/}{slds-lmu.github.io/lecture\_dl4nlp}}
\date{}

\begin{document}
\lecturechapter{GPT \&  Benchmarks}
\lecture{Deep Learning for NLP}

% ------------------------------------------------------------------------------

\begin{vbframe}{GPT: Ethical considerations}

\vfill

  \begin{itemize}
\item In general, a machine does not know (and
probably does not care) what consequences its words will have
in the real world.
  \begin{itemize}
\item Example: advice to someone expressing suicidal thoughts
    \end{itemize}
\item Text contains bias, language models learn that
bias and will act on it when deployed in the real world.
  \begin{itemize}
\item Discrimination against certain job applicants
    \end{itemize}
\item A future much better version of GPT could be
used by bad actors: spam, political manipulation, harassment
(e.g., on social media), academic fraud etc.
\item A future much better version of GPT could make a
lot of jobs redundant: journalism, marketing etc.
\item One partial solution: legal requirement to
disclose automatic generation (``Kennzeichungspflicht'')
    \end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{}

\vfill

  \begin{block}{GPT authors on APTs (advanced persistent
      threats, e.g., North Korea)}
\ldots language models may not be worth investing significant
resources in because there has been no convincing
demonstration that current language models are significantly
better than current methods for generating text, and because
methods for
``targeting'' or ``controlling'' the content of language models
are still at a very early stage.
    \end{block}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{GPT3's gender bias}

\vfill
			
  \begin{itemize}
\item Experiment: make GPT3 generate text in ``male''
and ``female'' contexts and find generated words more
correlated with one vs the other.
\item Male contexts: ``He was very \ldots'', ``He
would be described as \ldots''
\item Female contexts: ``She was very \ldots'', ``She
would be described as \ldots''
    \end{itemize}
    
\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Words generated by GPT3 highly correlated with male vs female contexts}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figure/genderbias.png}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{GPT3's race bias}

\vfill

  \begin{itemize}
\item Experiment (analogous to gender): make GPT3 generate text in racial
contexts and find generated words more
correlated with one vs the other.
\item Contexts: ``The RACE man was very \ldots'',
``The RACE woman was very \ldots'', ``People would describe
the RACE person as \ldots'' etc.
    \end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Sentiment of text  generated by GPT3 for racial contexts}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figure/racebias.png}
	\end{figure}

\vfill

\end{vbframe}


% ------------------------------------------------------------------------------

\begin{vbframe}{Words generated by GPT3 highly correlated with
  religions}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width=10cm]{figure/religionbias.png}
	\end{figure}

\vfill

\end{vbframe}


% ------------------------------------------------------------------------------

\begin{vbframe}{Bias: What to do?}

\vfill

  \begin{itemize}
\item Debias the biased model (huge literature on this)
\item Control training text (very hard to do in practice)
\item GPT3 authors: not really a problem NLP people
can address, need interdisciplinary approach
    \end{itemize}

\vfill

\end{vbframe}


% ------------------------------------------------------------------------------

\begin{vbframe}{GPT3 is not environmentally friendly}

\vfill

  \begin{block}{https://lambdalabs.com/blog/demystifying-gpt-3/}
      But to put things into perspective, GPT-3 175B model
      required 3.14E23 FLOPS of computing for training. Even
      at theoretical 28 TFLOPS for V100 and lowest 3 year
      reserved cloud pricing we could find, this will take
      355 GPU-years and cost \$4.6M for a single training
      run.
  \end{block}

\vfill

\end{vbframe}


% ------------------------------------------------------------------------------

\begin{vbframe}{Response to green concerns about GPT3}

\vfill

  \begin{itemize}
\item You only have to train the model once. If you
then use it a lot, that can be efficient.
\item Generating 100 pages of text with GPT3 costs a
few cents in energy -- perhaps ok?
\item Distill the model once it is trained (e.g., Distilbert)
    \end{itemize}
    
\vfill

\end{vbframe}

\endlecture
\end{document}
