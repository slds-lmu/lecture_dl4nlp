\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\newcommand{\titlefigure}{figure/elmo.jpg}
\newcommand{\learninggoals}{
\item Understand the contextualization of word embeddings
\item Get the intuition of feature-based Transfer Learning}

\title{Transfer Learning}
% \author{}
\institute{\href{https://slds-lmu.github.io/lecture_dl4nlp/}{slds-lmu.github.io/lecture\_dl4nlp}}
\date{}

\begin{document}
\lecturechapter{ELMo (Peters et al., 2018)}
\lecture{Deep Learning for NLP}

% ------------------------------------------------------------------------------

\begin{vbframe}{Recap: Word vectors}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width = 11cm]{figure/linear-relationships.png}\\ 
		\footnotesize{Source:} \href{https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space}{\footnotesize \it google}
	\end{figure}

	\begin{itemize}
		\item Information is encoded in (pre-)trained word embeddings
		\item Embeddings are used for tasks external to the training corpus
	\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Feature-based Transfer Learning}

\vfill

\textbf{Using word2vec:}
	
	\begin{enumerate}
		\item Self-supervised pre-training of word2vec ..
			\begin{itemize}
				\item Using a large, unannotated corpus
				\item Objective: CBOW or Skip-gram
			\end{itemize}
		.. and extract the stored knowledge (i.e. embedding)\\
		\item \textit{Alternative:} Download embeddings from the web,
		e.g. \url{https://code.google.com/archive/p/word2vec/}
		\item Perform a (supervised) task using the embeddings,
		e.g. Sentiment classification using an LSTM network
	\end{enumerate}
	
\textit{The stored knowledge from the pre-trained model is extracted as is
and is not further adapted to the actual domain/task of interest!}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Contextuality}

\vfill

\textbf{1st Generation of neural embeddings are "context-free":}

	\begin{itemize}
		\item Breakthrough paper by Mikolov et al, 2013 (Word2Vec)
		\item Followed by Pennington et al, 2014 (GloVe)
		\item Extension of Word2Vec by Bojanowski et al, 2016 (FastText)
	\end{itemize}
	
	\textbf{Why "Context-free"?}
	
	\begin{itemize}
		\item Models learn \textit{one single} embedding for each word
		\item Why could this possibly be problematic?
			\begin{itemize}
				\item "The \textit{default} setting of the function is xyz."
				\item "The probability of \textit{default} is rather high."
			\end{itemize}
		\item Would be nice to have different embeddings for these two occurrences
	\end{itemize}
	
\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Contextual embeddings}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width = 10cm]{figure/elmo-embedding-robin-williams.png}\\ 
		\footnotesize{Source:} \href{https://jalammar.github.io/illustrated-bert/}{\footnotesize \it Jay Alammar}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{ELMo \href{https://www.aclweb.org/anthology/N18-1202.pdf}{\beamergotobutton{Peters et al., 2018}}}

\vfill

\begin{itemize}
		\item Bidirectional language model (LM)
		\item Combines a forward LM $$p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} | t_{1}, t_{2}, \ldots, t_{k-1}\right)$$
					and a backward LM $$p\left(t_{1}, t_{2}, \ldots, t_{N}\right)=\prod_{k=1}^{N} p\left(t_{k} | t_{k+1}, t_{k+2}, \ldots, t_{N}\right)$$
					to arrive at the following loglikelihood:
					$$\begin{array}{l}
\sum_{k=1}^{N}\left(\log p\left(t_{k} | t_{1}, \ldots, t_{k-1} ; \Theta_{x}, \overrightarrow{\Theta}_{L S T M}, \Theta_{s}\right)\right. \\
\quad\left. +\log p\left(t_{k} | t_{k+1}, \ldots, t_{N} ; \Theta_{x}, \overleftarrow{\Theta}_{L S T M}, \Theta_{s}\right)\right)
\end{array}$$
	\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{ELMo embeddings}

\vfill

	\begin{itemize}
		\item Character-based (context-independent) token representations $$x_k^{LM}$$
		\item Two-layer biLSTM as main architecture:
			\begin{itemize}
				\item Two context-dependent token representations \textit{per layer}, i.e.
							$$\overrightarrow{\mathbf{h}}_{k, j}^{L M}\; \mbox{\&}\; \overleftarrow{\mathbf{h}}_{k, j}^{L M}\; \mbox{for the $k$-th token in the $j$-th layer.}$$
				\item Four context-dependent token representations in total: 
							$$\left\{\overrightarrow{\mathbf{h}}_{k, j}^{L M}, \overleftarrow{\mathbf{h}}_{k, j}^{L M} | j = 1, 2\right\}$$
			\end{itemize}
		\item Five representations per token in total:
					$$\begin{aligned}
R_{k} &=\left\{\mathbf{x}_{k}^{L M}, \overrightarrow{\mathbf{h}}_{k, j}^{L M}, \overleftarrow{\mathbf{h}}_{k, j}^{L M} | j=1, \ldots, L\right\} \\
&=\left\{\mathbf{h}_{k, j}^{L M} | j = 0, 1, 2\right\}
\end{aligned}$$
	\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Graphical representation}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width = 10cm]{figure/elmo-pretrained-bilm}\\ 
		\footnotesize{Source:} \href{https://slds-lmu.github.io/seminar_nlp_ss20/transfer-learning-for-nlp-i.html}{\footnotesize \it Carolin Becker}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Graphical representation}

\vfill
			
	\begin{figure}
		\centering
		\includegraphics[width = 10cm]{figure/elmo-pretrained-bilm-2}\\ 
		\footnotesize{Source:} \href{https://slds-lmu.github.io/seminar_nlp_ss20/transfer-learning-for-nlp-i.html}{\footnotesize \it Carolin Becker}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Task Adaption}

\vfill

\textbf{Including ELMo in downstream tasks:}

	\begin{itemize}
		\item Calculate task-specific weights of all five representations:
					$$\mathbf{E} \mathbf{L} \mathbf{M} \mathbf{o}_{k}^{t a s k}=E\left(R_{k} ; \Theta^{t a s k}\right)=\gamma^{t a s k} \sum_{j=0}^{L} s_{j}^{t a s k} \mathbf{h}_{k, j}^{L M},$$
					where the $\mathbf{h}_{k, j}^{L M}$ are \textbf{not trainable} anymore.
		\item Trainable parameters during the adaption:
			\begin{itemize}
				\item $s_{j}^{t a s k}$ are trainable (softmax-normalized) weights
				\item $\gamma^{t a s k}$ is a trainable scaling parameter
			\end{itemize}
	\end{itemize}

	\textbf{Advantages over context free-embeddings:}

	\begin{itemize}
		\item Task-specific model has access to \textit{multiple} representations of each token
		\item Model learns to which degree to use the different representations depending on the task at hand
	\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Task Adaption}

\vfill

	\begin{figure}
		\centering
		\includegraphics[width = 12cm]{figure/elmo-adaption}\\ 
		\footnotesize{Source:} \href{https://slds-lmu.github.io/seminar_nlp_ss20/transfer-learning-for-nlp-i.html}{\footnotesize \it Carolin Becker}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Performance}

\vfill
			
	\begin{figure}
		\centering
		\includegraphics[width = 12cm]{figure/elmo-sota.png}\\ 
		\footnotesize{Source:} \href{https://aclanthology.org/N18-1202.pdf}{\footnotesize \it Peters et al. (2018)}
	\end{figure}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\begin{vbframe}{Summary}

\vfill

	\begin{itemize}
		\item Embeddings are (bidirectionally!) contextualized \\
					(as opposed to word2vec)
		\item Embeddings are \textit{not} adapted to target domain/task \\
					(similar as for word2vec)
		\item Additional weights are learned for each downstream task \\
					(i.e. besides the embeddings, no shared knowledge across tasks)
	\end{itemize}

\vfill

\end{vbframe}

% ------------------------------------------------------------------------------

\endlecture
\end{document}
